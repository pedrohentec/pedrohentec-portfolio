schema: hugoblox/author/v1
slug: me
is_owner: true
name:
  display: Pedro Henrique  # ‚Üê SEU NOME COMPLETO
  given: Pedro
  family: pedrohentec  # ‚Üê SEU SOBRENOME
  alternate: ''
  pronunciation: ''
  pronouns: ''
postnominals: []
status:
  icon: "üé≤"
role: Junior Data Engineer
bio: |
  Data enthusiast with a passion for building robust data pipelines and orchestrating data in the cloud. 
  I work daily with GCP, Apache Airflow, and Python to transform data into business value.

affiliations:
  - name: ONR ‚Ä¢ Registro de Im√≥veis Eletr√¥nico    # ‚Üê SUA EMPRESA
    url: 'https://www.onr.org.br/' # ‚Üê URL DA SUA EMPRESA

links:
  - icon: envelope
    url: mailto:pedrohentec@gmail.com  # ‚Üê SEU EMAIL
    label: E-mail Me
  - icon: brands/github
    url: https://github.com/pedrohentec  # ‚Üê SEU GITHUB
    label: GitHub
  - icon: brands/linkedin
    url: https://www.linkedin.com/in/pedrohentec/  # ‚Üê SEU LINKEDIN
    label: LinkedIn
  - icon: brands/youtube
    url: https://youtube.com/@pedrohentec  # ‚Üê SEU YOUTUBE
    label: YouTube
  - icon: hero/tv
    url: https://www.twitch.tv/pedrohentec
    label: Twitch

interests:
  - Data Pipelines
  - Cloud Computing (GCP)
  - Data Orchestration
  - SQL & Analytics

education:
  - degree: Data Science  # ‚Üê SUA FORMA√á√ÉO
    institution: UNOPAR   # ‚Üê SUA UNIVERSIDADE
    start: ''  # ‚Üê ANO IN√çCIO
    end: ''    # ‚Üê ANO FIM

experience:
  - role: Junior Data Engineer
    org: ONR ‚Ä¢ Registro de Im√≥veis Eletr√¥nico  # ‚Üê SUA EMPRESA
    start: 2025-01-06  # ‚Üê DATA IN√çCIO
    summary: |
      I work in the development and monitoring of data pipelines in a GCP environment, focusing on performance, governance, and reliability of information. 
      I use Apache Beam and Dataflow for data orchestration in BigQuery, applying good modularization and asynchronous processing practices, reducing costs in a cloud environment and having a similar or improved impact.

      ‚óè Creation of pipelines with Apache Beam (Python) in Dataflow, processing data in batches and streaming.

      ‚óè Automatic validation of tables and partitions in BigQuery, with generation of dynamic models from JSON files.

      ‚óè Monitoring of jobs via API (Dataflow and BigQuery), focusing on status, metrics, and data integrity.

      ‚óè Data governance and classification with Dataplex, aligned with LGPD (Brazilian General Data Protection Law).

      ‚óè Optimization and refactoring of legacy pipelines for greater efficiency and reusability.

      

  - role: Data Engineer (Trainee)
    org: A3Data
    start: 2024-07-01
    end: 2025-03-01
    summary: |
      I worked as a Data Engineer on projects in an AWS environment, focusing on building and optimizing large-scale data pipelines. I worked on data ingestion, transformation, and delivery processes, directly contributing to the efficiency and governance of the solutions.

      ‚óè Development of pipelines with Spark, SQL, and Python in an AWS EMR environment, orchestrated by Airflow.

      ‚óè Optimization of queries and data flows using Athena, with data stored in S3, ensuring performance and cost-effectiveness.

      ‚óè Use of Docker and Kubernetes (EKS) for packaging and deploying data applications.

      ‚óè Support in implementing best practices for version control with Git/GitHub and code modularization for reuse and maintenance.

      ‚óè Active participation in data requirements analysis, contributing technical insights to strategic decisions.

skills:
  - name: Engenharia de Dados
    items:
      - label: Python
        level: 5
      - label: SQL
        level: 4
      - label: Apache Airflow
        level: 3
      - label: BigQuery
        level: 3
      - label: Docker
        level: 3
      - label: GCP Dataflow
        level: 2

languages:
  - name: Portuguese
    level: 5
    label: Native
  - name: English
    level: 3
    label: Intermediate

awards: []